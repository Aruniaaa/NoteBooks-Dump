{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm.auto import tqdm\n",
    "import torchvision.models as models\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "\n",
    "batch_size = 32 \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epochs = 3\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.1, 0.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize\n",
    "])\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    imagenet_normalize\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "for param in model.features[-5:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 1)  \n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epochs, loader, model, loss_fn, optimizer):\n",
    "    total_batches = len(loader)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        total_epoch_loss = 0\n",
    "        print(f\"\\n -------- Epoch {epoch} --------\")\n",
    "        \n",
    "        for batch, (X, Y) in enumerate(loader):\n",
    "            model.train()\n",
    "\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "            Y_pred = model(X)\n",
    "            Y = Y.unsqueeze(1).float()\n",
    "            loss = loss_fn(Y_pred, Y)\n",
    "            total_epoch_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        total_epoch_loss /= total_batches\n",
    "        print()\n",
    "        print(f\"Avg training loss: {total_epoch_loss:.2f}\")\n",
    "\n",
    "\n",
    "def test_loop(loader, model, loss_fn):\n",
    "    \n",
    "    total_batches = len(loader)\n",
    "\n",
    "    model.eval()\n",
    "    total_loss, total_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for X, Y in loader:\n",
    "            \n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "            Y_pred = model(X)\n",
    "            Y = Y.unsqueeze(1).float()\n",
    "            loss = loss_fn(Y_pred, Y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(Y_pred)\n",
    "            preds = (probs > 0.5).float()\n",
    "            correct = (preds == Y).sum().item()\n",
    "            total_acc += correct\n",
    "\n",
    "        total_loss /= total_batches\n",
    "        total_acc = total_acc / len(loader.dataset)\n",
    "\n",
    "    return total_acc\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=r\"C:\\Users\\HP\\Desktop\\phone-detector\\Train-6\", transform=train_transforms)\n",
    "test_dataset  = datasets.ImageFolder(root=r\"C:\\Users\\HP\\Desktop\\phone-detector\\Test-2\",  transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune import TuneConfig\n",
    "\n",
    "def custom_trial_dir_name(trial):\n",
    "    return f\"objective_lr{trial.config['lr']:.4f}_d{trial.config['dropout']}_f{trial.config['features']}\"\n",
    "\n",
    "\n",
    "def objective(config): \n",
    "    model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1) \n",
    "    \n",
    "    for param in model.features[config['features']:].parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(25088, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(config['dropout']),\n",
    "        nn.Linear(512, 1)  \n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {\"params\": model.features[config['features_to_train']:].parameters(), \"lr\": config['lr']},  \n",
    "        {\"params\": model.classifier.parameters(), \"lr\": config['clr']},     \n",
    "    ], weight_decay=config['weight_decay'])\n",
    "\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "    train_loop(config['epochs'], train_loader, model, loss_fn, optimizer)\n",
    "    acc = test_loop(test_loader, model, loss_fn)\n",
    "    tune.report({\"mean_accuracy\": acc})  \n",
    "\n",
    "\n",
    "search_space = {\"lr\": tune.loguniform(1e-5,  1e-3),  \n",
    "                \"dropout\" : tune.choice([0.2, 0.3, 0.4, 0.5]),\n",
    "                \"clr\" : tune.loguniform(1e-5,  1e-3),\n",
    "                \"weight_decay\" : tune.loguniform(1e-5,  1e-3),\n",
    "                \"features\" : tune.choice([-2, -3, -4, -5, -6, -7]),\n",
    "                \"features_to_train\" : tune.choice([-2, -3, -4, -5, -6, -7]),\n",
    "                \"epochs\" : tune.choice([2, 4, 6, 8, 10])\n",
    "                }\n",
    "\n",
    "algo = OptunaSearch() \n",
    "\n",
    "tuner = tune.Tuner(  \n",
    "    objective,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        search_alg=algo,\n",
    "        trial_dirname_creator=custom_trial_dir_name\n",
    "    ),\n",
    "    run_config=tune.RunConfig(\n",
    "        stop={\"training_iteration\": 1},\n",
    "    ),\n",
    "    param_space=search_space,\n",
    ")\n",
    "results = tuner.fit()\n",
    "print(\"Best config is:\", results.get_best_result().config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
